{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce870116",
   "metadata": {},
   "source": [
    "# GNN for Recommendation: LightGCN vs Feature GNN vs Hybrid Fusion\n",
    "\n",
    "1) **LightGCN** (graph-only, no features, no nonlinearities)\n",
    "2) **Feature-aware GNN** (GraphSAGE) using node features + nonlinearities\n",
    "3) **Hybrid**: LightGCN embeddings fused with node features downstream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164d722",
   "metadata": {},
   "source": [
    "## Synthetic graph used throughout\n",
    "\n",
    "**Users:** 0..4  \n",
    "**Items:** 5..10  \n",
    "\n",
    "Edges (user → item):\n",
    "- U0 → I5, I6\n",
    "- U1 → I6\n",
    "- U2 → I7\n",
    "- U3 → I8\n",
    "- U4 → I9, I10\n",
    "\n",
    "We make the graph **undirected** for message passing by adding reverse edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing, SAGEConv\n",
    "\n",
    "torch.manual_seed(7)\n",
    "\n",
    "num_users = 5\n",
    "num_items = 6\n",
    "num_nodes = num_users + num_items\n",
    "\n",
    "# Directed edges user->item (positives)\n",
    "edge_ui = torch.tensor([\n",
    "    [0, 0, 1, 2, 3, 4, 4],\n",
    "    [5, 6, 6, 7, 8, 9, 10]\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Make undirected for message passing\n",
    "edge_index = torch.cat([edge_ui, edge_ui.flip(0)], dim=1)\n",
    "\n",
    "data = Data(edge_index=edge_index, num_nodes=num_nodes)\n",
    "\n",
    "edge_ui, edge_index.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9689d",
   "metadata": {},
   "source": [
    "## Shared utility: link prediction loss\n",
    "\n",
    "We score a (u, i) pair by dot product of embeddings:\n",
    "\n",
    "`score(u, i) = <e_u, e_i>`\n",
    "\n",
    "Training uses a simple logistic loss:\n",
    "- positives = observed user→item edges\n",
    "- negatives = random user–item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_score(emb, src, dst):\n",
    "    return (emb[src] * emb[dst]).sum(dim=-1)\n",
    "\n",
    "def sample_negatives(n_samples, num_users, num_nodes):\n",
    "    u = torch.randint(0, num_users, (n_samples,))\n",
    "    v = torch.randint(num_users, num_nodes, (n_samples,))\n",
    "    return u, v\n",
    "\n",
    "def bce_link_loss(emb, pos_src, pos_dst, neg_src, neg_dst):\n",
    "    pos = dot_score(emb, pos_src, pos_dst)\n",
    "    neg = dot_score(emb, neg_src, neg_dst)\n",
    "    loss = -(torch.log(torch.sigmoid(pos) + 1e-9) +\n",
    "             torch.log(torch.sigmoid(-neg) + 1e-9)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac2ce7",
   "metadata": {},
   "source": [
    "## 1) LightGCN (graph-only)\n",
    "\n",
    "**LightGCN design constraints**:\n",
    "- No node features: nodes start as trainable embeddings only\n",
    "- No nonlinear transforms: propagation is pure neighbor aggregation\n",
    "\n",
    "This isolates collaborative filtering signal from graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(MessagePassing):\n",
    "    def __init__(self, num_nodes, emb_dim=16):\n",
    "        super().__init__(aggr='mean')\n",
    "        self.embedding = nn.Embedding(num_nodes, emb_dim)\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        x = self.embedding.weight  # no features, just embeddings\n",
    "        x = self.propagate(edge_index, x=x)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efa1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgcn(edge_index, pos_edges, epochs=200, emb_dim=16, lr=0.01):\n",
    "    model = LightGCN(num_nodes=num_nodes, emb_dim=emb_dim)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    pos_src, pos_dst = pos_edges[0], pos_edges[1]\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        opt.zero_grad()\n",
    "        emb = model(edge_index)\n",
    "        neg_src, neg_dst = sample_negatives(pos_src.numel(), num_users, num_nodes)\n",
    "        loss = bce_link_loss(emb, pos_src, pos_dst, neg_src, neg_dst)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return model, model(edge_index).detach()\n",
    "\n",
    "pos_edges = edge_ui  # directed positives (user->item)\n",
    "\n",
    "light_model, light_emb = train_lightgcn(edge_index, pos_edges, epochs=200, emb_dim=16, lr=0.01)\n",
    "light_emb[:2], light_emb[num_users:num_users+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d64ecb",
   "metadata": {},
   "source": [
    "## 2) Feature-aware GNN (GraphSAGE)\n",
    "\n",
    "To add features:\n",
    "- Provide a feature matrix `x` for all nodes\n",
    "- Use a feature-aware GNN layer (GraphSAGE here)\n",
    "- Include nonlinearities (ReLU)\n",
    "\n",
    "Here features are random vectors (mechanics only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d303c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGNN(nn.Module):\n",
    "    def __init__(self, in_dim=8, hidden_dim=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_feature_gnn(edge_index, pos_edges, epochs=200, in_dim=8, hidden_dim=16, lr=0.01):\n",
    "    model = FeatureGNN(in_dim=in_dim, hidden_dim=hidden_dim)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Fake node features (stand-in for text/image/metadata embeddings)\n",
    "    x = torch.randn(num_nodes, in_dim)\n",
    "\n",
    "    pos_src, pos_dst = pos_edges[0], pos_edges[1]\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        opt.zero_grad()\n",
    "        emb = model(x, edge_index)\n",
    "        neg_src, neg_dst = sample_negatives(pos_src.numel(), num_users, num_nodes)\n",
    "        loss = bce_link_loss(emb, pos_src, pos_dst, neg_src, neg_dst)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return model, x.detach(), model(x, edge_index).detach()\n",
    "\n",
    "sage_model, node_x, sage_emb = train_feature_gnn(edge_index, pos_edges, epochs=200, in_dim=8, hidden_dim=16, lr=0.01)\n",
    "sage_emb[:2], sage_emb[num_users:num_users+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83be0e7e",
   "metadata": {},
   "source": [
    "## 3) Hybrid fusion (graph embeddings + features downstream)\n",
    "\n",
    "Common large-scale pattern:\n",
    "1) Learn graph embeddings from interactions (LightGCN)\n",
    "2) Compute side features separately (content/metadata)\n",
    "3) Fuse downstream (concat + MLP here)\n",
    "\n",
    "This keeps graph training simple while still using rich features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d632551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRanker(nn.Module):\n",
    "    def __init__(self, graph_dim=16, feat_dim=8, hidden=32):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(graph_dim + feat_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, graph_dim)  # project back to embedding space\n",
    "        )\n",
    "\n",
    "    def forward(self, graph_emb, node_x):\n",
    "        z = torch.cat([graph_emb, node_x], dim=-1)\n",
    "        return self.mlp(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hybrid(edge_index, pos_edges, epochs=200, graph_dim=16, feat_dim=8, lr=0.01):\n",
    "    # Pretrain LightGCN embeddings (fixed graph encoder)\n",
    "    _, graph_emb = train_lightgcn(edge_index, pos_edges, epochs=200, emb_dim=graph_dim, lr=0.01)\n",
    "\n",
    "    # Fake features (stand-in for content/metadata)\n",
    "    node_x = torch.randn(num_nodes, feat_dim)\n",
    "\n",
    "    ranker = HybridRanker(graph_dim=graph_dim, feat_dim=feat_dim, hidden=32)\n",
    "    opt = torch.optim.Adam(ranker.parameters(), lr=lr)\n",
    "\n",
    "    pos_src, pos_dst = pos_edges[0], pos_edges[1]\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        opt.zero_grad()\n",
    "        fused_emb = ranker(graph_emb, node_x)\n",
    "        neg_src, neg_dst = sample_negatives(pos_src.numel(), num_users, num_nodes)\n",
    "        loss = bce_link_loss(fused_emb, pos_src, pos_dst, neg_src, neg_dst)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return graph_emb.detach(), node_x.detach(), ranker, ranker(graph_emb, node_x).detach()\n",
    "\n",
    "hy_graph_emb, hy_x, hy_ranker, hy_emb = train_hybrid(edge_index, pos_edges, epochs=200, graph_dim=16, feat_dim=8, lr=0.01)\n",
    "hy_emb[:2], hy_emb[num_users:num_users+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df776e61",
   "metadata": {},
   "source": [
    "## Edge weights (mechanics only)\n",
    "\n",
    "Edges can carry weights (e.g., interaction strength, time decay).\n",
    "This notebook attaches an `edge_weight` tensor as a placeholder; a full weighted\n",
    "propagation implementation is intentionally omitted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c091239",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_weight = torch.ones(edge_index.size(1))\n",
    "edge_weight[:10] *= 2.0  # pretend first few edges are \"stronger\"\n",
    "edge_weight[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc611a55",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "- **LightGCN**: graph-only collaborative filtering; scalable; no features by design\n",
    "- **Feature GNN (GraphSAGE/GAT)**: integrates features; more expressive; heavier compute\n",
    "- **Hybrid**: graph embeddings + content/metadata fused downstream; common at scale"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
