# A Unified Approach to Interpreting Model Predictions (SHAP)

Link: https://arxiv.org/abs/1705.07874

Interpretability reference.

Core concept:
additive feature attribution  
local explanations  

Typical use:
inspect individual predictions  
compare feature contributions  

Failure mode:
treating explanations as causal  
over-interpreting global patterns  

Practical constraint:
computational cost  
approximation required for large models  

Primary role:
debugging
communication
