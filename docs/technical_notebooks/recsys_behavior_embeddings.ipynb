{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "id": "fd15386c",
      "cell_type": "markdown",
      "source": [
        "# Embedding Methods for Recommenders\n",
        "\n",
        "| System Design  |\n",
        "|----|\n",
        "|*Offline*  \n",
        "User events → **embedding training** → item/user vectors (versioned) |\n",
        "|*Storage*  \n",
        "Embedding store + ANN index (same version) |\n",
        "|*Online*  \n",
        "Request → user vector → ANN top-K → ranking → rules → response |\n",
        "\n",
        "  \n",
        "<br>\n",
        "\n",
        "Embedding families used in recommender systems:\n",
        "\n",
        "1. **Co-occurrence / PMI + SVD** (fast baseline)\n",
        "2. **Item2Vec** (sequence-based)\n",
        "3. **Graph embeddings via random walks** (structure)\n",
        "4. **Multimodal content embeddings fusion** (text/image signals, cold start)\n"
      ],
      "metadata": {
        "id": "fd15386c"
      }
    },
    {
      "id": "a7b41137",
      "cell_type": "markdown",
      "source": [
        "## 0) Setup"
      ],
      "metadata": {
        "id": "a7b41137"
      }
    },
    {
      "id": "4231a396",
      "cell_type": "code",
      "metadata": {
        "id": "4231a396"
      },
      "execution_count": 1,
      "source": [
        "\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "from collections import Counter\n",
        "import math\n",
        "import time\n",
        "\n",
        "rng = default_rng(7)\n",
        "\n",
        "def l2_normalize(x, axis=1, eps=1e-12):\n",
        "    n = np.linalg.norm(x, axis=axis, keepdims=True)\n",
        "    return x / np.maximum(n, eps)\n",
        "\n",
        "def recall_at_k(query_emb, item_emb, positives, k=20):\n",
        "    \"\"\"Mean Recall@K for one positive per query (fast + simple).\"\"\"\n",
        "    q = l2_normalize(query_emb, axis=1)\n",
        "    it = l2_normalize(item_emb, axis=1)\n",
        "    scores = q @ it.T\n",
        "    topk = np.argpartition(-scores, kth=k-1, axis=1)[:, :k]\n",
        "    hits = 0\n",
        "    for i, pos in enumerate(positives):\n",
        "        if int(pos) in topk[i]:\n",
        "            hits += 1\n",
        "    return hits / len(positives)\n"
      ],
      "outputs": []
    },
    {
      "id": "afc48a5d",
      "cell_type": "markdown",
      "source": [
        "## 1) Synthetic data: users, items, sessions\n",
        "Sessions are represented as item sequences with latent structure + popularity"
      ],
      "metadata": {
        "id": "afc48a5d"
      }
    },
    {
      "id": "ae1cc684",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae1cc684",
        "outputId": "55a2228d-7d88-403f-a13b-1b9ec7e59675"
      },
      "execution_count": 2,
      "source": [
        "\n",
        "# Size knobs\n",
        "n_users = 1500\n",
        "n_items = 400\n",
        "latent_dim = 16\n",
        "\n",
        "# Latent factors that drive \"true\" affinity\n",
        "U_true = rng.normal(size=(n_users, latent_dim)).astype(np.float32)\n",
        "V_true = rng.normal(size=(n_items, latent_dim)).astype(np.float32)\n",
        "\n",
        "# Item popularity (long tail)\n",
        "pop = rng.power(a=2.0, size=n_items).astype(np.float32)\n",
        "pop = pop / pop.sum()\n",
        "\n",
        "def sample_item_for_user(u_id):\n",
        "    # mixture: latent affinity + popularity\n",
        "    scores = U_true[u_id] @ V_true.T\n",
        "    scores = (scores - scores.max())\n",
        "    p_aff = np.exp(scores).astype(np.float64)\n",
        "    p_aff = p_aff / p_aff.sum()\n",
        "    p = 0.8 * p_aff + 0.2 * pop\n",
        "    return int(rng.choice(n_items, p=p))\n",
        "\n",
        "# Build sessions (sequences). Scores: views/clicks in one visit.\n",
        "n_sessions = 7000\n",
        "session_len = 20\n",
        "\n",
        "sessions = []\n",
        "for _ in range(n_sessions):\n",
        "    u = int(rng.integers(0, n_users))\n",
        "    seq = [sample_item_for_user(u) for _ in range(session_len)]\n",
        "    sessions.append(seq)\n",
        "\n",
        "flat = [i for s in sessions for i in s]\n",
        "item_counts = Counter(flat)\n",
        "\n",
        "print(\"sessions:\", len(sessions), \"avg len:\", round(np.mean([len(s) for s in sessions]), 2))\n",
        "print(\"top items:\", item_counts.most_common(5))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sessions: 7000 avg len: 20.0\n",
            "top items: [(102, 2898), (156, 2463), (308, 2029), (28, 2012), (139, 1981)]\n"
          ]
        }
      ]
    },
    {
      "id": "b98e614c",
      "cell_type": "markdown",
      "source": [
        "## 2) Method A: Co-occurrence → PMI → SVD embedding\n",
        "Baseline, often hard to beat.\n",
        "\n",
        "Steps:\n",
        "- Count item-item co-occurrence within a context window\n",
        "- Convert to PPMI (positive PMI)\n",
        "- Run SVD to get dense vectors"
      ],
      "metadata": {
        "id": "b98e614c"
      }
    },
    {
      "id": "d4d24ec7",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4d24ec7",
        "outputId": "7cd89575-9ca0-4ecf-bcca-672c7ba2048b"
      },
      "execution_count": 3,
      "source": [
        "\n",
        "def build_cooccurrence(sessions, n_items, window=5):\n",
        "    C = np.zeros((n_items, n_items), dtype=np.float32)\n",
        "    for seq in sessions:\n",
        "        L = len(seq)\n",
        "        for i, center in enumerate(seq):\n",
        "            left = max(0, i-window)\n",
        "            right = min(L, i+window+1)\n",
        "            for j in range(left, right):\n",
        "                if j == i:\n",
        "                    continue\n",
        "                context = seq[j]\n",
        "                C[center, context] += 1.0\n",
        "    return C\n",
        "\n",
        "t0 = time.time()\n",
        "C = build_cooccurrence(sessions, n_items, window=5)\n",
        "print(\"cooc built in\", round(time.time()-t0, 2), \"s; nnz≈\", int((C > 0).sum()))\n",
        "\n",
        "row_sum = C.sum(axis=1, keepdims=True)\n",
        "col_sum = C.sum(axis=0, keepdims=True)\n",
        "total = C.sum()\n",
        "\n",
        "eps = 1e-8\n",
        "p_ij = C / (total + eps)\n",
        "p_i = row_sum / (total + eps)\n",
        "p_j = col_sum / (total + eps)\n",
        "\n",
        "PMI = np.log((p_ij + eps) / (p_i @ p_j + eps))\n",
        "PPMI = np.maximum(PMI, 0.0).astype(np.float32)\n",
        "\n",
        "k = 32\n",
        "U, S, VT = np.linalg.svd(PPMI, full_matrices=False)\n",
        "item_emb_ppmi = (U[:, :k] * S[:k]).astype(np.float32)\n",
        "\n",
        "print(\"item_emb_ppmi:\", item_emb_ppmi.shape, \"S[0:5]:\", np.round(S[:5], 3))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cooc built in 0.61 s; nnz≈ 127644\n",
            "item_emb_ppmi: (400, 32) S[0:5]: [95.062 27.541 26.924 26.232 25.471]\n"
          ]
        }
      ]
    },
    {
      "id": "ab0cd4af",
      "cell_type": "markdown",
      "source": [
        "### Sanity check for retrieval\n",
        "Predict next item from previous item. Fast sanity check that embeddings carry structure."
      ],
      "metadata": {
        "id": "ab0cd4af"
      }
    },
    {
      "id": "a8edcc83",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8edcc83",
        "outputId": "2c140af0-4b5f-47a7-9156-e8fadbdaa292"
      },
      "execution_count": 4,
      "source": [
        "\n",
        "pairs = []\n",
        "for seq in sessions[:3000]:\n",
        "    for a, b in zip(seq[:-1], seq[1:]):\n",
        "        pairs.append((a, b))\n",
        "\n",
        "pairs = np.array(pairs, dtype=np.int32)\n",
        "prev_items = pairs[:, 0]\n",
        "next_items = pairs[:, 1]\n",
        "\n",
        "r20 = recall_at_k(item_emb_ppmi[prev_items], item_emb_ppmi, next_items, k=20)\n",
        "print(\"PPMI+SVD Recall@20:\", round(r20, 4))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPMI+SVD Recall@20: 0.3354\n"
          ]
        }
      ]
    },
    {
      "id": "b0f9e2f0",
      "cell_type": "markdown",
      "source": [
        "## 3) Method B: Item2Vec (skip-gram + negative sampling)\n",
        "Sequence-based embeddings.\n",
        "\n",
        "Implementation:\n",
        "- Build (center, context) pairs from sessions\n",
        "- Train embeddings with negative sampling (small SGD)"
      ],
      "metadata": {
        "id": "b0f9e2f0"
      }
    },
    {
      "id": "8a906d67",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a906d67",
        "outputId": "6baa041c-3e4e-4480-8b9d-f77835d1e720"
      },
      "execution_count": 5,
      "source": [
        "\n",
        "def build_skipgram_pairs(seqs, window=4, max_pairs=250_000):\n",
        "    pairs = []\n",
        "    for seq in seqs:\n",
        "        L = len(seq)\n",
        "        for i, center in enumerate(seq):\n",
        "            left = max(0, i-window)\n",
        "            right = min(L, i+window+1)\n",
        "            for j in range(left, right):\n",
        "                if j == i:\n",
        "                    continue\n",
        "                pairs.append((center, seq[j]))\n",
        "                if len(pairs) >= max_pairs:\n",
        "                    return np.array(pairs, dtype=np.int32)\n",
        "    return np.array(pairs, dtype=np.int32)\n",
        "\n",
        "pairs_sg = build_skipgram_pairs(sessions, window=4, max_pairs=220_000)\n",
        "print(\"skipgram pairs:\", pairs_sg.shape)\n",
        "\n",
        "counts = np.bincount(np.array(flat, dtype=np.int32), minlength=n_items).astype(np.float64)\n",
        "neg_dist = counts ** 0.75\n",
        "neg_dist = neg_dist / neg_dist.sum()\n",
        "\n",
        "def train_item2vec(pairs, n_items, dim=32, lr=0.05, epochs=2, neg_k=10, seed=7, steps=120_000):\n",
        "    rng = default_rng(seed)\n",
        "    W_in = (0.01 * rng.normal(size=(n_items, dim))).astype(np.float32)\n",
        "    W_out = (0.01 * rng.normal(size=(n_items, dim))).astype(np.float32)\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "    idx = np.arange(len(pairs))\n",
        "    for ep in range(epochs):\n",
        "        rng.shuffle(idx)\n",
        "        loss = 0.0\n",
        "        for t in idx[:steps]:\n",
        "            c, o = pairs[t]\n",
        "            v_c = W_in[c]\n",
        "            v_o = W_out[o]\n",
        "\n",
        "            # positive label = 1\n",
        "            score_pos = float(v_c @ v_o)\n",
        "            p_pos = sigmoid(score_pos)\n",
        "            loss += -math.log(max(p_pos, 1e-10))\n",
        "            grad_pos = (p_pos - 1.0)\n",
        "\n",
        "            g_in = grad_pos * v_o\n",
        "            g_out = grad_pos * v_c\n",
        "\n",
        "            # negatives label = 0\n",
        "            negs = rng.choice(n_items, size=neg_k, replace=True, p=neg_dist)\n",
        "            for n in negs:\n",
        "                v_n = W_out[n]\n",
        "                score_neg = float(v_c @ v_n)\n",
        "                p_neg = sigmoid(score_neg)\n",
        "                loss += -math.log(max(1.0 - p_neg, 1e-10))\n",
        "                grad_neg = p_neg\n",
        "                g_in += grad_neg * v_n\n",
        "                W_out[n] -= lr * (grad_neg * v_c)\n",
        "\n",
        "            W_in[c] -= lr * g_in\n",
        "            W_out[o] -= lr * g_out\n",
        "\n",
        "        print(f\"epoch {ep+1}/{epochs} avg_loss≈{loss/steps:.4f}\")\n",
        "    return W_in\n",
        "\n",
        "t0 = time.time()\n",
        "item_emb_i2v = train_item2vec(pairs_sg, n_items, dim=32, lr=0.04, epochs=2, neg_k=8, seed=7)\n",
        "print(\"trained in\", round(time.time()-t0, 2), \"s\")\n",
        "\n",
        "r20 = recall_at_k(item_emb_i2v[prev_items], item_emb_i2v, next_items, k=20)\n",
        "print(\"Item2Vec Recall@20:\", round(r20, 4))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skipgram pairs: (220000, 2)\n",
            "epoch 1/2 avg_loss≈3.1329\n",
            "epoch 2/2 avg_loss≈2.5874\n",
            "trained in 53.6 s\n",
            "Item2Vec Recall@20: 0.2991\n"
          ]
        }
      ]
    },
    {
      "id": "9c707c1f",
      "cell_type": "markdown",
      "source": [
        "## 4) Method C: Graph embeddings (random walks + skip-gram)\n",
        "Build an item-item graph from co-occurrence, run random walks, then train Item2Vec on the walks.\n",
        "\n",
        "Captures longer-range structure than a fixed window."
      ],
      "metadata": {
        "id": "9c707c1f"
      }
    },
    {
      "id": "01e22704",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01e22704",
        "outputId": "1036647c-de0e-4c4c-ad04-59fe4c1c425e"
      },
      "execution_count": 6,
      "source": [
        "\n",
        "# Adjacency from co-occurrence counts: top-N neighbors per item\n",
        "topN = 30\n",
        "adj = [[] for _ in range(n_items)]\n",
        "for i in range(n_items):\n",
        "    row = C[i].copy()\n",
        "    row[i] = 0\n",
        "    nbrs = np.argpartition(-row, kth=topN)[:topN]\n",
        "    nbrs = nbrs[row[nbrs] > 0]\n",
        "    adj[i] = nbrs.tolist()\n",
        "\n",
        "def random_walks(adj, n_walks=6, walk_len=25, seed=7):\n",
        "    rng = default_rng(seed)\n",
        "    walks = []\n",
        "    for start in range(len(adj)):\n",
        "        if not adj[start]:\n",
        "            continue\n",
        "        for _ in range(n_walks):\n",
        "            w = [start]\n",
        "            cur = start\n",
        "            for _ in range(walk_len - 1):\n",
        "                nbrs = adj[cur]\n",
        "                if not nbrs:\n",
        "                    break\n",
        "                cur = int(rng.choice(nbrs))\n",
        "                w.append(cur)\n",
        "            walks.append(w)\n",
        "    return walks\n",
        "\n",
        "walks = random_walks(adj, n_walks=6, walk_len=25, seed=7)\n",
        "print(\"walks:\", len(walks), \"avg len:\", round(np.mean([len(w) for w in walks]), 2))\n",
        "\n",
        "pairs_walk = build_skipgram_pairs(walks, window=3, max_pairs=240_000)\n",
        "print(\"walk skipgram pairs:\", pairs_walk.shape)\n",
        "\n",
        "t0 = time.time()\n",
        "item_emb_graph = train_item2vec(pairs_walk, n_items, dim=32, lr=0.04, epochs=2, neg_k=8, seed=9)\n",
        "print(\"trained in\", round(time.time()-t0, 2), \"s\")\n",
        "\n",
        "r20 = recall_at_k(item_emb_graph[prev_items], item_emb_graph, next_items, k=20)\n",
        "print(\"Graph-walk Recall@20:\", round(r20, 4))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "walks: 2400 avg len: 25.0\n",
            "walk skipgram pairs: (240000, 2)\n",
            "epoch 1/2 avg_loss≈3.2574\n",
            "epoch 2/2 avg_loss≈2.8827\n",
            "trained in 56.69 s\n",
            "Graph-walk Recall@20: 0.2667\n"
          ]
        }
      ]
    },
    {
      "id": "ce05e0db",
      "cell_type": "markdown",
      "source": [
        "## 5) Method D: Fuse with content-based embeddings\n",
        "In practice we often have precomputed text/image embeddings. We can use them directly (cold start), or fuse with behavior embeddings.\n",
        "\n",
        "Here we simulate text and image vectors correlated with item latent factors, then compare retrieval from fused embeddings."
      ],
      "metadata": {
        "id": "ce05e0db"
      }
    },
    {
      "id": "55c08ac2",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55c08ac2",
        "outputId": "18dd3470-0fb1-44ec-ae58-c03373d0eaa2"
      },
      "execution_count": 7,
      "source": [
        "\n",
        "d_mm = 64\n",
        "A_txt = rng.normal(size=(latent_dim, d_mm)).astype(np.float32)\n",
        "A_img = rng.normal(size=(latent_dim, d_mm)).astype(np.float32)\n",
        "\n",
        "text_emb = (V_true @ A_txt + 0.2 * rng.normal(size=(n_items, d_mm))).astype(np.float32)\n",
        "img_emb  = (V_true @ A_img + 0.2 * rng.normal(size=(n_items, d_mm))).astype(np.float32)\n",
        "\n",
        "# Simple fusion: concat + fixed linear projection\n",
        "X = np.concatenate([l2_normalize(text_emb), l2_normalize(img_emb)], axis=1)\n",
        "proj = rng.normal(size=(X.shape[1], 32)).astype(np.float32)\n",
        "item_emb_mm = (X @ proj).astype(np.float32)\n",
        "\n",
        "r20 = recall_at_k(item_emb_mm[prev_items], item_emb_mm, next_items, k=20)\n",
        "print(\"Multimodal Recall@20:\", round(r20, 4))\n",
        "\n",
        "# Fuse behavior + multimodal (common in production)\n",
        "item_emb_fused = l2_normalize(np.concatenate([item_emb_i2v, item_emb_mm], axis=1))\n",
        "r20 = recall_at_k(item_emb_fused[prev_items], item_emb_fused, next_items, k=20)\n",
        "print(\"Fused (behavior + multimodal) Recall@20:\", round(r20, 4))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multimodal Recall@20: 0.3164\n",
            "Fused (behavior + multimodal) Recall@20: 0.3194\n"
          ]
        }
      ]
    },
    {
      "id": "4c7f6d8b",
      "cell_type": "markdown",
      "source": [
        "## 6) Production notes\n",
        "**Emdedding choice**\n",
        "- Need fast + stable: PPMI+SVD\n",
        "- Strong sequences: Item2Vec\n",
        "- Graph structure matters: walk-based graph embeddings\n",
        "- Cold start: multimodal content embeddings, then fuse with behavior\n",
        "\n",
        "**Common failure modes**\n",
        "- Popularity collapse: everything maps to head items\n",
        "- Leakage in session construction: future events sneaking in\n",
        "- Staleness: catalog shifts faster than refresh cadence\n",
        "\n",
        "**Serving**\n",
        "- Store vectors in embedding store + query via ANN index\n",
        "- Version vectors + ANN index with model + feature snapshot\n",
        "- Monitor drift + retrieval coverage + define rollback triggers"
      ],
      "metadata": {
        "id": "4c7f6d8b"
      }
    }
  ]
}