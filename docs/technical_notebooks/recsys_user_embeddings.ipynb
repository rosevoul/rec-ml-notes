{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "id": "b5df83e4",
      "cell_type": "markdown",
      "source": [
        "# User Embeddings\n",
        "\n",
        "- **Minimal**: user vector = weighted average of recent item embeddings\n",
        "- **Modern**: learned user encoder (two-tower style) over user history\n"
      ],
      "metadata": {
        "id": "b5df83e4"
      }
    },
    {
      "id": "dd00228e",
      "cell_type": "markdown",
      "source": [
        "## 0) Helpers"
      ],
      "metadata": {
        "id": "dd00228e"
      }
    },
    {
      "id": "4f21400a",
      "cell_type": "code",
      "metadata": {
        "id": "4f21400a"
      },
      "execution_count": 1,
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from numpy.random import default_rng\n",
        "\n",
        "rng = default_rng(3)\n",
        "\n",
        "def l2_normalize(x, axis=1, eps=1e-12):\n",
        "    n = np.linalg.norm(x, axis=axis, keepdims=True)\n",
        "    return x / np.maximum(n, eps)\n",
        "\n",
        "def recall_at_k(query_emb, item_emb, positives, k=20):\n",
        "    q = l2_normalize(np.asarray(query_emb, dtype=np.float32))\n",
        "    it = l2_normalize(np.asarray(item_emb, dtype=np.float32))\n",
        "    S = q @ it.T\n",
        "    topk = np.argpartition(-S, kth=k-1, axis=1)[:, :k]\n",
        "    hits = 0\n",
        "    for i, pos in enumerate(positives):\n",
        "        if int(pos) in topk[i]:\n",
        "            hits += 1\n",
        "    return hits / len(positives)\n"
      ],
      "outputs": []
    },
    {
      "id": "4a4c0df9",
      "cell_type": "markdown",
      "source": [
        "## 1) Synthetic interactions"
      ],
      "metadata": {
        "id": "4a4c0df9"
      }
    },
    {
      "id": "e5079d08",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5079d08",
        "outputId": "d9e22cf4-1f62-4ef4-d5c7-80f67872b56f"
      },
      "execution_count": 2,
      "source": [
        "n_users = 3000\n",
        "n_items = 1500\n",
        "d = 48\n",
        "\n",
        "U_true = rng.normal(size=(n_users, d)).astype(np.float32)\n",
        "V_true = rng.normal(size=(n_items, d)).astype(np.float32)\n",
        "\n",
        "pop = rng.power(a=2.0, size=n_items).astype(np.float32)\n",
        "pop = pop / pop.sum()\n",
        "\n",
        "def sigmoid(x): return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def sample_item(u_vec):\n",
        "    scores = (u_vec @ V_true.T).astype(np.float32)\n",
        "    scores = scores - scores.max()\n",
        "    p_aff = np.exp(scores).astype(np.float64)\n",
        "    p_aff = p_aff / p_aff.sum()\n",
        "    p = 0.85 * p_aff + 0.15 * pop\n",
        "    return int(rng.choice(n_items, p=p))\n",
        "\n",
        "T = 30\n",
        "histories = []\n",
        "for u in range(n_users):\n",
        "    drift = (0.4 * rng.normal(size=(d,))).astype(np.float32)\n",
        "    seq = []\n",
        "    for t in range(T):\n",
        "        u_vec = U_true[u] + (drift if t > T//2 else 0.0)\n",
        "        seq.append(sample_item(u_vec))\n",
        "    histories.append(seq)\n",
        "\n",
        "histories = np.array(histories, dtype=np.int32)\n",
        "print(\"histories:\", histories.shape)\n",
        "print(\"example history:\", histories[0][:10])\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "histories: (3000, 30)\n",
            "example history: [1348  355  880  446 1348 1348 1348 1348 1348  862]\n"
          ]
        }
      ]
    },
    {
      "id": "615418a5",
      "cell_type": "markdown",
      "source": [
        "## 2) Item embedding space (given)"
      ],
      "metadata": {
        "id": "615418a5"
      }
    },
    {
      "id": "7a31eb11",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a31eb11",
        "outputId": "d9009f56-9c3b-47c6-c985-f65298a66664"
      },
      "execution_count": 3,
      "source": [
        "item_emb = (V_true + 0.15 * rng.normal(size=V_true.shape).astype(np.float32)).astype(np.float32)\n",
        "item_emb = l2_normalize(item_emb)\n",
        "\n",
        "targets = histories[:, -1]\n",
        "prefix = histories[:, :-1]\n",
        "print(\"prefix:\", prefix.shape, \"targets:\", targets.shape)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prefix: (3000, 29) targets: (3000,)\n"
          ]
        }
      ]
    },
    {
      "id": "7f0e23a3",
      "cell_type": "markdown",
      "source": [
        "## 3) Minimal user embedding: weighted average"
      ],
      "metadata": {
        "id": "7f0e23a3"
      }
    },
    {
      "id": "d40ccd51",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d40ccd51",
        "outputId": "0c5251cf-56a4-47a0-aec8-ea5ee5cfb96d"
      },
      "execution_count": 4,
      "source": [
        "def user_embed_avg(prefix_items, item_emb, decay=0.05):\n",
        "    U, L = prefix_items.shape\n",
        "    t = np.arange(L, dtype=np.float32)\n",
        "    w = np.exp(decay * (t - (L - 1))).astype(np.float32)  # newest ~1\n",
        "    w = w / (w.sum() + 1e-12)\n",
        "    X = item_emb[prefix_items]  # [U, L, d]\n",
        "    u = (X * w[None, :, None]).sum(axis=1)\n",
        "    return l2_normalize(u)\n",
        "\n",
        "u_avg = user_embed_avg(prefix, item_emb, decay=0.07)\n",
        "\n",
        "print(\"Avg user embedding  Recall@20:\", round(recall_at_k(u_avg, item_emb, targets, k=20), 4))\n",
        "print(\"Avg user embedding  Recall@50:\", round(recall_at_k(u_avg, item_emb, targets, k=50), 4))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg user embedding  Recall@20: 0.7387\n",
            "Avg user embedding  Recall@50: 0.7727\n"
          ]
        }
      ]
    },
    {
      "id": "6e49d651",
      "cell_type": "markdown",
      "source": [
        "## 4) Minimal upgrade: short-term + long-term mix"
      ],
      "metadata": {
        "id": "6e49d651"
      }
    },
    {
      "id": "98e03ef5",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98e03ef5",
        "outputId": "b6a496fb-0b9e-4026-9dc2-3f333504373d"
      },
      "execution_count": 5,
      "source": [
        "u_long = user_embed_avg(prefix, item_emb, decay=0.01)\n",
        "u_short = user_embed_avg(prefix, item_emb, decay=0.15)\n",
        "u_mix = l2_normalize(0.4 * u_long + 0.6 * u_short)\n",
        "\n",
        "print(\"Mixed user embedding Recall@20:\", round(recall_at_k(u_mix, item_emb, targets, k=20), 4))\n",
        "print(\"Mixed user embedding Recall@50:\", round(recall_at_k(u_mix, item_emb, targets, k=50), 4))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mixed user embedding Recall@20: 0.738\n",
            "Mixed user embedding Recall@50: 0.7717\n"
          ]
        }
      ]
    },
    {
      "id": "e2d078d2",
      "cell_type": "markdown",
      "source": [
        "## 5) Modern: learned user encoder (two-tower style)"
      ],
      "metadata": {
        "id": "e2d078d2"
      }
    },
    {
      "id": "53ea2876",
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ea2876",
        "outputId": "106eebc1-e943-433d-c60d-c4acbf952fdf"
      },
      "execution_count": 6,
      "source": [
        "# Train a small user encoder (two-tower style) using in-batch negatives\n",
        "L = 20\n",
        "train_users = 2200\n",
        "\n",
        "X_hist = histories[:train_users, :L]\n",
        "y_next = histories[:train_users, L]\n",
        "\n",
        "hist_vecs = item_emb[X_hist]                # [U, L, d]\n",
        "mean_vec = hist_vecs.mean(axis=1)\n",
        "last_vec = hist_vecs[:, -1, :]\n",
        "weights = np.linspace(0.5, 1.0, L, dtype=np.float32)[None, :, None]\n",
        "short_vec = l2_normalize((hist_vecs * weights).sum(axis=1))\n",
        "\n",
        "feat = np.concatenate([mean_vec, last_vec, short_vec], axis=1).astype(np.float32)  # [U, 3d]\n",
        "feat = l2_normalize(feat)\n",
        "\n",
        "h = 128\n",
        "W1 = (0.02 * rng.normal(size=(feat.shape[1], h))).astype(np.float32)\n",
        "b1 = np.zeros((h,), dtype=np.float32)\n",
        "W2 = (0.02 * rng.normal(size=(h, d))).astype(np.float32)\n",
        "b2 = np.zeros((d,), dtype=np.float32)\n",
        "\n",
        "def relu(x): return np.maximum(x, 0.0)\n",
        "\n",
        "def forward(feat):\n",
        "    z1 = relu(feat @ W1 + b1)\n",
        "    u = z1 @ W2 + b2\n",
        "    return l2_normalize(u)\n",
        "\n",
        "def train(epochs=6, lr=0.18, batch=256, seed=4):\n",
        "    global W1, b1, W2, b2\n",
        "    rng2 = default_rng(seed)\n",
        "    n = feat.shape[0]\n",
        "    idx = np.arange(n)\n",
        "    for ep in range(epochs):\n",
        "        rng2.shuffle(idx)\n",
        "        loss = 0.0\n",
        "        for start in range(0, n, batch):\n",
        "            bidx = idx[start:start+batch]\n",
        "            Xb = feat[bidx]\n",
        "            yb = y_next[bidx]\n",
        "\n",
        "            Ub = forward(Xb)            # [B, d]\n",
        "            Vb = item_emb[yb]           # [B, d]\n",
        "\n",
        "            S = Ub @ Vb.T               # [B, B]\n",
        "            S = S - S.max(axis=1, keepdims=True)\n",
        "            P = np.exp(S).astype(np.float32)\n",
        "            P = P / (P.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "            diag = np.diag(P)\n",
        "            loss += float((-np.log(diag + 1e-12)).mean())\n",
        "\n",
        "            G = P\n",
        "            G[np.arange(len(bidx)), np.arange(len(bidx))] -= 1.0\n",
        "            G = G / len(bidx)\n",
        "\n",
        "            dUb = G @ Vb\n",
        "\n",
        "            z1 = relu(Xb @ W1 + b1)\n",
        "            mask = (z1 > 0).astype(np.float32)\n",
        "\n",
        "            dW2 = (z1.T @ dUb).astype(np.float32)\n",
        "            db2 = dUb.sum(axis=0).astype(np.float32)\n",
        "\n",
        "            dz1 = (dUb @ W2.T) * mask\n",
        "            dW1 = (Xb.T @ dz1).astype(np.float32)\n",
        "            db1 = dz1.sum(axis=0).astype(np.float32)\n",
        "\n",
        "            W2 -= lr * dW2\n",
        "            b2 -= lr * db2\n",
        "            W1 -= lr * dW1\n",
        "            b1 -= lr * db1\n",
        "\n",
        "        print(f\"epoch {ep+1}/{epochs} loss≈{loss/(n/batch):.4f}\")\n",
        "\n",
        "train()\n",
        "\n",
        "eval_users = np.arange(train_users, n_users, dtype=np.int32)\n",
        "Xe = histories[eval_users, :L]\n",
        "ye = histories[eval_users, L]\n",
        "\n",
        "hv = item_emb[Xe]\n",
        "mean_vec = hv.mean(axis=1)\n",
        "last_vec = hv[:, -1, :]\n",
        "weights = np.linspace(0.5, 1.0, L, dtype=np.float32)[None, :, None]\n",
        "short_vec = l2_normalize((hv * weights).sum(axis=1))\n",
        "\n",
        "feat_e = l2_normalize(np.concatenate([mean_vec, last_vec, short_vec], axis=1).astype(np.float32))\n",
        "u_learned = forward(feat_e)\n",
        "\n",
        "print(\"Learned user encoder Recall@20:\", round(recall_at_k(u_learned, item_emb, ye, k=20), 4))\n",
        "print(\"Learned user encoder Recall@50:\", round(recall_at_k(u_learned, item_emb, ye, k=50), 4))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/6 loss≈5.7526\n",
            "epoch 2/6 loss≈5.7335\n",
            "epoch 3/6 loss≈5.7151\n",
            "epoch 4/6 loss≈5.6972\n",
            "epoch 5/6 loss≈5.6818\n",
            "epoch 6/6 loss≈5.6640\n",
            "Learned user encoder Recall@20: 0.0788\n",
            "Learned user encoder Recall@50: 0.1388\n"
          ]
        }
      ]
    },
    {
      "id": "ed2171e2",
      "cell_type": "markdown",
      "source": [
        "## Production notes\n",
        "- Weighted averages are strong and cheap, we can ship them first.\n",
        "- Learned user encoders help when intent shifts fast or personalization matters at retrieval.\n",
        "- Keep stable normalization, similarity, versioning with the ANN index.\n",
        "- Cache user vectors and bound tail latency, so we always have cold-start fallbacks.\n"
      ],
      "metadata": {
        "id": "ed2171e2"
      }
    }
  ]
}